import streamlit as st
import pandas as pd
from supabase import create_client, Client
from datetime import datetime
import io
import unicodedata

# --- 1. Supabase ì ‘ì† ì„¤ì • ---
url: str = st.secrets["SUPABASE_URL"]
key: str = st.secrets["SUPABASE_KEY"]
supabase: Client = create_client(url, key)

def super_clean(val):
    """ìì¬ë²ˆí˜¸ì˜ ëª¨ë“  ë…¸ì´ì¦ˆ ì œê±°: ê³µë°±, ì „ê°/ë°˜ê° í†µì¼, ëŒ€ë¬¸ìí™”"""
    if pd.isna(val): return ""
    # 1. ë¬¸ìì—´í™” ë° ì–‘ë ê³µë°± ì œê±°
    s = str(val).strip()
    # 2. ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (ì „ê° ë¬¸ìë¥¼ ë°˜ê°ìœ¼ë¡œ, í˜¼ìš©ëœ ìëª¨ìŒ ê²°í•© ë“± í•´ê²°)
    s = unicodedata.normalize('NFKC', s)
    # 3. ì¤‘ê°„ì— ì„ì¸ ëª¨ë“  ê³µë°± ì œê±° ë° ëŒ€ë¬¸ìí™”
    s = "".join(s.split()).upper()
    # 4. ì—‘ì…€ ìˆ«ì í”ì  ì œê±°
    if s.endswith('.0'): s = s[:-2]
    return s

st.set_page_config(page_title="AS TAT ì‹œìŠ¤í…œ", layout="wide")
st.title("â±ï¸ AS TAT ë¶„ì„ ì‹œìŠ¤í…œ (ê¸°ëŠ¥ ë³µêµ¬ ë° ì •ë°€í™”)")

# --- 2. ì‚¬ì´ë“œë°”: ê´€ë¦¬ ë° ì´ˆê¸°í™” ---
with st.sidebar:
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    
    # ì‹¤ì‹œê°„ DB ìƒíƒœ í‘œì‹œ
    try:
        m_count = supabase.table("master_data").select("ìì¬ë²ˆí˜¸", count="exact").execute()
        st.info(f"ğŸ“Š ë§ˆìŠ¤í„° DB ë“±ë¡: {m_count.count} ê±´")
    except: pass

    st.subheader("1. ë§ˆìŠ¤í„° ê´€ë¦¬")
    master_file = st.file_uploader("ë§ˆìŠ¤í„° ì—‘ì…€ ì—…ë¡œë“œ", type=['xlsx'])
    if master_file and st.button("ğŸš€ ë§ˆìŠ¤í„° ê°±ì‹ ", use_container_width=True):
        m_df = pd.read_excel(master_file, dtype=str)
        m_data = []
        for _, row in m_df.iterrows():
            mat_no = super_clean(row.iloc[0])
            if not mat_no: continue
            m_data.append({
                "ìì¬ë²ˆí˜¸": mat_no,
                "ê³µê¸‰ì—…ì²´ëª…": str(row.iloc[5]).strip() if not pd.isna(row.iloc[5]) else "ì •ë³´ì—†ìŒ",
                "ë¶„ë¥˜êµ¬ë¶„": str(row.iloc[10]).strip() if not pd.isna(row.iloc[10]) else "ì •ë³´ì—†ìŒ"
            })
        if m_data:
            supabase.table("master_data").delete().neq("ìì¬ë²ˆí˜¸", "EMPTY").execute()
            for i in range(0, len(m_data), 200):
                supabase.table("master_data").insert(m_data[i:i+200]).execute()
            st.success("âœ… ë§ˆìŠ¤í„° ê°±ì‹  ì™„ë£Œ")
            st.rerun()

    st.divider()
    st.subheader("2. ì •ë³´ ë³´ì •")
    if st.button("ğŸ”„ ë¯¸ë“±ë¡ ì¬ë§¤ì¹­ ì‹¤í–‰", use_container_width=True):
        with st.spinner("ì •ë°€ ëŒ€ì¡° ì¤‘..."):
            m_res = supabase.table("master_data").select("*").execute()
            m_lookup = {r['ìì¬ë²ˆí˜¸']: r for r in m_res.data}
            h_res = supabase.table("as_history").select("id, ìì¬ë²ˆí˜¸").execute()
            up_cnt = 0
            for row in h_res.data:
                info = m_lookup.get(super_clean(row['ìì¬ë²ˆí˜¸']))
                if info:
                    supabase.table("as_history").update({
                        "ê³µê¸‰ì—…ì²´ëª…": info['ê³µê¸‰ì—…ì²´ëª…'], "ë¶„ë¥˜êµ¬ë¶„": info['ë¶„ë¥˜êµ¬ë¶„']
                    }).eq("id", row['id']).execute()
                    up_cnt += 1
            st.success(f"âœ… {up_cnt}ê±´ ë³´ì • ì™„ë£Œ")
            st.rerun()

    st.divider()
    st.subheader("3. ì´ˆê¸°í™”")
    if st.button("âš ï¸ ì‹œìŠ¤í…œ ì „ì²´ ì´ˆê¸°í™”", type="primary", use_container_width=True):
        supabase.table("as_history").delete().neq("id", -1).execute()
        supabase.table("master_data").delete().neq("ìì¬ë²ˆí˜¸", "EMPTY").execute()
        st.warning("ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun()

# --- 3. ì…ê³ /ì¶œê³  ì²˜ë¦¬ ---
tab1, tab2 = st.tabs(["ğŸ“¥ AS ì…ê³ ", "ğŸ“¤ AS ì¶œê³ "])

with tab1:
    in_file = st.file_uploader("ì…ê³  ì—‘ì…€", type=['xlsx'], key="in")
    if in_file and st.button("ì…ê³  ì²˜ë¦¬"):
        df = pd.read_excel(in_file, dtype=str)
        as_in = df[df.iloc[:, 0].str.contains('A/S ì² ê±°', na=False)].copy()
        m_res = supabase.table("master_data").select("*").execute()
        m_lookup = {r['ìì¬ë²ˆí˜¸']: r for r in m_res.data}
        recs = []
        for _, row in as_in.iterrows():
            mat = super_clean(row.iloc[3])
            m = m_lookup.get(mat)
            recs.append({
                "ì••ì¶•ì½”ë“œ": str(row.iloc[7]).strip(), "ìì¬ë²ˆí˜¸": mat,
                "ê·œê²©": str(row.iloc[5]).strip(), "ìƒíƒœ": "ì¶œê³  ëŒ€ê¸°",
                "ê³µê¸‰ì—…ì²´ëª…": m['ê³µê¸‰ì—…ì²´ëª…'] if m else "ë¯¸ë“±ë¡",
                "ë¶„ë¥˜êµ¬ë¶„": m['ë¶„ë¥˜êµ¬ë¶„'] if m else "ë¯¸ë“±ë¡",
                "ì…ê³ ì¼": pd.to_datetime(row.iloc[1]).strftime('%Y-%m-%d')
            })
        if recs:
            for i in range(0, len(recs), 200):
                supabase.table("as_history").insert(recs[i:i+200]).execute()
            st.success("ì…ê³  ì™„ë£Œ")
            st.rerun()

with tab2:
    out_file = st.file_uploader("ì¶œê³  ì—‘ì…€", type=['xlsx'], key="out")
    if out_file and st.button("ì¶œê³  ì²˜ë¦¬"):
        df = pd.read_excel(out_file, dtype=str)
        as_out = df[df.iloc[:, 3].str.contains('AS ì¹´í†¤ ë°•ìŠ¤', na=False)].copy()
        for _, row in as_out.iterrows():
            key, date = str(row.iloc[10]).strip(), pd.to_datetime(row.iloc[6])
            target = supabase.table("as_history").select("id, ì…ê³ ì¼").match({"ì••ì¶•ì½”ë“œ": key, "ìƒíƒœ": "ì¶œê³  ëŒ€ê¸°"}).order("ì…ê³ ì¼").limit(1).execute()
            if target.data:
                in_dt = pd.to_datetime(target.data[0]['ì…ê³ ì¼'])
                tat = round((date - in_dt).total_seconds() / 86400, 2)
                supabase.table("as_history").update({"ì¶œê³ ì¼": date.strftime('%Y-%m-%d'), "tat": tat, "ìƒíƒœ": "ì¶œê³  ì™„ë£Œ"}).eq("id", target.data[0]['id']).execute()
        st.success("ì¶œê³  ì™„ë£Œ")
        st.rerun()

# --- 4. ë¦¬í¬íŠ¸ (í•„í„° ë° ë‹¤ìš´ë¡œë“œ ë³µêµ¬) ---
st.divider()
try:
    res = supabase.table("as_history").select("*").order("ì…ê³ ì¼", desc=True).execute()
    data = pd.DataFrame(res.data)
    if not data.empty:
        st.subheader("ğŸ“Š í˜„í™© ë¦¬í¬íŠ¸")
        # í•„í„°ë§ ì„¹ì…˜
        c1, c2, c3 = st.columns(3)
        v_f = c1.multiselect("ê³µê¸‰ì—…ì²´", sorted(data['ê³µê¸‰ì—…ì²´ëª…'].unique()))
        g_f = c2.multiselect("ë¶„ë¥˜êµ¬ë¶„", sorted(data['ë¶„ë¥˜êµ¬ë¶„'].unique()))
        s_f = c3.multiselect("ìƒíƒœ", sorted(data['ìƒíƒœ'].unique()))
        
        dff = data.copy()
        if v_f: dff = dff[dff['ê³µê¸‰ì—…ì²´ëª…'].isin(v_f)]
        if g_f: dff = dff[dff['ë¶„ë¥˜êµ¬ë¶„'].isin(g_f)]
        if s_f: dff = dff[dff['ìƒíƒœ'].isin(s_f)]

        # ì§€í‘œ
        m1, m2, m3 = st.columns(3)
        m1.metric("ì¡°íšŒ ê±´ìˆ˜", f"{len(dff)} ê±´")
        m2.metric("ë¯¸ë“±ë¡ ê±´ìˆ˜", f"{len(dff[dff['ê³µê¸‰ì—…ì²´ëª…'] == 'ë¯¸ë“±ë¡'])} ê±´")
        m3.metric("í‰ê·  TAT", f"{round(pd.to_numeric(dff['tat']).mean(), 1) if 'tat' in dff else 0} ì¼")

        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            dff.to_excel(writer, index=False)
        st.download_button("ğŸ“¥ í•„í„°ë§ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", buffer.getvalue(), "AS_Analysis_Report.xlsx")

        st.dataframe(dff, use_container_width=True, hide_index=True)
except: pass
